* Observations on covariance / stimuli relationships

* Used forced choice assignment of positions to dots. 

  What you want to do is assign a detected position to a particular dot first. Your graphs then have to incorporate every possible iteration instead of a subset. What you want to do is provide a graph with X amount of nodes. 

** RULES: If there is already an edge going from node M to node N, do not add an edge N to M. Also no loops: i.e. If 1 -> 2, and 2-> 3, can't have 3 -> 1. Can assure there are no loops by stopping at N-1 edges. First enter a randomly ordered list of ints of length X. Are going to ask "is this node a child of any of the other dots? (i.e. it's cdr)" Have a separate recursive matching function that takes the candidate, its cdr, and asks the logical statements above, adding edges if true, not if false. It will return the graph. Recur on the cdr for candidate children. Stop when there are X-1 edges or the candidate children are empty. 

** Probabilities: Any given graph has to have a probability. I think this is currently true. I think they can all be reduced to unconnected, single connected, two connect to upper parent, parent-child-child. 
* Simplifying the Model
** Position
   Simplified position by getting rid of normal and uniform samples and using uniform_discrete samples. 
   When not inheriting from parent, position is a broader distribution. When inheriting from parent, tighter. 

** Velocity
   Only give X velocity. Each covariance function has a fixed param. Every observed velocity will have a score from a mvnormal for a given velocity type. Therefore, we only need to enumerate positions, velocity types, and trees now. 

* Marco suggestions:
** Role of uncertainty -- can have Hidden dots. 
   One task could be trying to figure out if there is a third dot somewhere in between. 
   Marco's idea is to have a timeseries draw per node, but also have an observed timeseries
   which would be generated by sampling independent gaussian noise around the pointwise sum of the
   latent timeseries for all nodes from the root to the node in question. 

* Observations on effects of tree
** Want to capture in model that constant inheriting constant can sometimes be perceived as not a group. This is easy to find. Importance sampling with ~75 samples yields significant probability in the "no group" classification.

** Also want to show that as the dots get further apart, even if they share some motion, i tend to de-group, and have some uncertainty lie in the occurances where prolonged co-position seems to have a grouping effect. 
